{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading Data From Diffrent sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we Will convert a Json file or Json data into (String) .... again try to convert a String into Json File or Json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nStringIO in Python :-\\nStringIO is a class in the io module that provides an in-memory stream for text I/O. It allows you to work with strings as if they were file-like objects. This is particularly useful when you need to manipulate text data without creating temporary files on disk.\\n\\nKey Features of StringIO\\nIn-Memory File-Like Object: Acts like a file, but everything is kept in memory.\\nRead and Write Operations: You can read from and write to a StringIO object just as you would with a regular file.\\nNo Disk I/O: Speeds up operations by avoiding disk access.\\nUseful for Testing: Ideal for simulating file operations in a controlled environment.\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO ## \n",
    "\"\"\"\n",
    "\n",
    "StringIO in Python :-\n",
    "StringIO is a class in the io module that provides an in-memory stream for text I/O. It allows you to work with strings as if they were file-like objects. This is particularly useful when you need to manipulate text data without creating temporary files on disk.\n",
    "\n",
    "Key Features of StringIO\n",
    "In-Memory File-Like Object: Acts like a file, but everything is kept in memory.\n",
    "Read and Write Operations: You can read from and write to a StringIO object just as you would with a regular file.\n",
    "No Disk I/O: Speeds up operations by avoiding disk access.\n",
    "Useful for Testing: Ideal for simulating file operations in a controlled environment.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = '{\"employee_name\": \"James\", \"email\": \"james@gmail.com\", \"job_profile\": [{\"title1\":\"Team Lead\", \"title2\":\"Sr. Developer\"}]}'\n",
    "## This is a Json data ...as you see in the form of Key and Value pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_name</th>\n",
       "      <th>email</th>\n",
       "      <th>job_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>james@gmail.com</td>\n",
       "      <td>{'title1': 'Team Lead', 'title2': 'Sr. Develop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_name            email  \\\n",
       "0         James  james@gmail.com   \n",
       "\n",
       "                                         job_profile  \n",
       "0  {'title1': 'Team Lead', 'title2': 'Sr. Develop...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### In order to read this data in the string and Convert into dataFrame then \n",
    "df=pd.read_json(StringIO(Data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"employee_name\":{\"0\":\"James\"},\"email\":{\"0\":\"james@gmail.com\"},\"job_profile\":{\"0\":{\"title1\":\"Team Lead\",\"title2\":\"Sr. Developer\"}}}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we try to again to convert thid data Frame into json \n",
    "df.to_json()\n",
    "# This json method have one By-default parameter called 'Orient' , and meaning of Orient is -> index ...... It has a Structure that I have shown below in below cell , see the Actual structure of \"Orient \" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\":{\"employee_name\":\"James\",\"email\":\"james@gmail.com\",\"job_profile\":{\"title1\":\"Team Lead\",\"title2\":\"Sr. Developer\"}}}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_json(orient='index') # This is By-deault structure of \"orient\" which is a parameter inside JSON \n",
    "# It wikk take 0 commom as comon index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"employee_name\":\"James\",\"email\":\"james@gmail.com\",\"job_profile\":{\"title1\":\"Team Lead\",\"title2\":\"Sr. Developer\"}}]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## In a case we don't want the index. only want records then we can print that records only\n",
    "df.to_json(orient='records') \n",
    "# You can see only records gets printed not the index ,,, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW WE WILL SEE HOW TO READ URL OF CSV/HTTTP/HTML/XLX ALL THIS FILES HOW TO READ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",header=None)\n",
    "\n",
    "# This a Dataset of Any Bank and everything... we have copy that url from google and pasted here , here (header=None ) for now we don't want any header in the Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## After reading the data , print the head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Also we have another example realted to wine csv\n",
    "df.to_csv(\"wine.csv\") \n",
    "## This is used to write something \"wine.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.938202</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
       "mean     1.938202   13.000618    2.336348    2.366517   19.494944   99.741573   \n",
       "std      0.775035    0.811827    1.117146    0.274344    3.339564   14.282484   \n",
       "min      1.000000   11.030000    0.740000    1.360000   10.600000   70.000000   \n",
       "25%      1.000000   12.362500    1.602500    2.210000   17.200000   88.000000   \n",
       "50%      2.000000   13.050000    1.865000    2.360000   19.500000   98.000000   \n",
       "75%      3.000000   13.677500    3.082500    2.557500   21.500000  107.000000   \n",
       "max      3.000000   14.830000    5.800000    3.230000   30.000000  162.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
       "mean     2.295112    2.029270    0.361854    1.590899    5.058090    0.957449   \n",
       "std      0.625851    0.998859    0.124453    0.572359    2.318286    0.228572   \n",
       "min      0.980000    0.340000    0.130000    0.410000    1.280000    0.480000   \n",
       "25%      1.742500    1.205000    0.270000    1.250000    3.220000    0.782500   \n",
       "50%      2.355000    2.135000    0.340000    1.555000    4.690000    0.965000   \n",
       "75%      2.800000    2.875000    0.437500    1.950000    6.200000    1.120000   \n",
       "max      3.880000    5.080000    0.660000    3.580000   13.000000    1.710000   \n",
       "\n",
       "               12           13  \n",
       "count  178.000000   178.000000  \n",
       "mean     2.611685   746.893258  \n",
       "std      0.709990   314.907474  \n",
       "min      1.270000   278.000000  \n",
       "25%      1.937500   500.500000  \n",
       "50%      2.780000   673.500000  \n",
       "75%      3.170000   985.000000  \n",
       "max      4.000000  1680.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "\n",
    "## YOU CAN APPLY ALL YOUR PREVIOUS LOGIC ON THIS FILE AND PERFORM ALL THE OPEATIONS WE SAW PREVIOUSLY , YOU CAN APPLY LOGIC OF THAT ALL OPEARTIONS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' NOTE:- DATA/DATASET/FILES MAY CHANGE BUT LOGIC REMAINS THE SAME , YOU NEED TO PERFORME THE LOGIC ONLY ...'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" NOTE:- DATA/DATASET/FILES MAY CHANGE BUT LOGIC REMAINS THE SAME , YOU NEED TO PERFORME THE LOGIC ONLY ...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in d:\\pythoncode\\venv\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in d:\\pythoncode\\venv\\lib\\site-packages (from html5lib) (1.17.0)\n",
      "Requirement already satisfied: webencodings in d:\\pythoncode\\venv\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\pythoncode\\venv\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\pythoncode\\venv\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: lxml in d:\\pythoncode\\venv\\lib\\site-packages (5.3.0)\n"
     ]
    }
   ],
   "source": [
    "### NOW WE SEE HOW TO READ HTML files and read them and find insights from them \n",
    "## Before that to read the HTML file we need to do installation some libaries or import something \n",
    "\n",
    "!pip install html5lib\n",
    "!pip install beautifulsoup4\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Cert</th>\n",
       "      <th>Aquiring Institution</th>\n",
       "      <th>Closing Date</th>\n",
       "      <th>Fund  Sort ascending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The First National Bank of Lindsay</td>\n",
       "      <td>Lindsay</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>4134</td>\n",
       "      <td>First Bank &amp; Trust Co., Duncan, OK</td>\n",
       "      <td>October 18, 2024</td>\n",
       "      <td>10547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Republic First Bank dba Republic Bank</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>27332</td>\n",
       "      <td>Fulton Bank, National Association</td>\n",
       "      <td>April 26, 2024</td>\n",
       "      <td>10546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citizens Bank</td>\n",
       "      <td>Sac City</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>8758</td>\n",
       "      <td>Iowa Trust &amp; Savings Bank</td>\n",
       "      <td>November 3, 2023</td>\n",
       "      <td>10545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heartland Tri-State Bank</td>\n",
       "      <td>Elkhart</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>25851</td>\n",
       "      <td>Dream First Bank, N.A.</td>\n",
       "      <td>July 28, 2023</td>\n",
       "      <td>10544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First Republic Bank</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>California</td>\n",
       "      <td>59017</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>May 1, 2023</td>\n",
       "      <td>10543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Signature Bank</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>57053</td>\n",
       "      <td>Flagstar Bank, N.A.</td>\n",
       "      <td>March 12, 2023</td>\n",
       "      <td>10540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Silicon Valley Bank</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>California</td>\n",
       "      <td>24735</td>\n",
       "      <td>First Citizens Bank &amp; Trust Company</td>\n",
       "      <td>March 10, 2023</td>\n",
       "      <td>10539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Almena State Bank</td>\n",
       "      <td>Almena</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>15426</td>\n",
       "      <td>Equity Bank</td>\n",
       "      <td>October 23, 2020</td>\n",
       "      <td>10538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>First City Bank of Florida</td>\n",
       "      <td>Fort Walton Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>16748</td>\n",
       "      <td>United Fidelity Bank, fsb</td>\n",
       "      <td>October 16, 2020</td>\n",
       "      <td>10537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The First State Bank</td>\n",
       "      <td>Barboursville</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>14361</td>\n",
       "      <td>MVB Bank, Inc.</td>\n",
       "      <td>April 3, 2020</td>\n",
       "      <td>10536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Bank Name               City          State  \\\n",
       "0     The First National Bank of Lindsay            Lindsay       Oklahoma   \n",
       "1  Republic First Bank dba Republic Bank       Philadelphia   Pennsylvania   \n",
       "2                          Citizens Bank           Sac City           Iowa   \n",
       "3               Heartland Tri-State Bank            Elkhart         Kansas   \n",
       "4                    First Republic Bank      San Francisco     California   \n",
       "5                         Signature Bank           New York       New York   \n",
       "6                    Silicon Valley Bank        Santa Clara     California   \n",
       "7                      Almena State Bank             Almena         Kansas   \n",
       "8             First City Bank of Florida  Fort Walton Beach        Florida   \n",
       "9                   The First State Bank      Barboursville  West Virginia   \n",
       "\n",
       "    Cert                 Aquiring Institution      Closing Date  \\\n",
       "0   4134   First Bank & Trust Co., Duncan, OK  October 18, 2024   \n",
       "1  27332    Fulton Bank, National Association    April 26, 2024   \n",
       "2   8758            Iowa Trust & Savings Bank  November 3, 2023   \n",
       "3  25851               Dream First Bank, N.A.     July 28, 2023   \n",
       "4  59017            JPMorgan Chase Bank, N.A.       May 1, 2023   \n",
       "5  57053                  Flagstar Bank, N.A.    March 12, 2023   \n",
       "6  24735  First Citizens Bank & Trust Company    March 10, 2023   \n",
       "7  15426                          Equity Bank  October 23, 2020   \n",
       "8  16748            United Fidelity Bank, fsb  October 16, 2020   \n",
       "9  14361                       MVB Bank, Inc.     April 3, 2020   \n",
       "\n",
       "   Fund  Sort ascending  \n",
       "0                 10547  \n",
       "1                 10546  \n",
       "2                 10545  \n",
       "3                 10544  \n",
       "4                 10543  \n",
       "5                 10540  \n",
       "6                 10539  \n",
       "7                 10538  \n",
       "8                 10537  \n",
       "9                 10536  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/\"\n",
    "df=pd.read_html(url)\n",
    "df[0]\n",
    "# Here Data is so vast you can print its index only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mobile country code</th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO 3166</th>\n",
       "      <th>Mobile network codes</th>\n",
       "      <th>National MNC authority</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289</td>\n",
       "      <td>A Abkhazia</td>\n",
       "      <td>GE-AB</td>\n",
       "      <td>List of mobile network codes in Abkhazia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCC is not listed by ITU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>List of mobile network codes in Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276</td>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>List of mobile network codes in Albania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>List of mobile network codes in Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>544</td>\n",
       "      <td>American Samoa (United States of America)</td>\n",
       "      <td>AS</td>\n",
       "      <td>List of mobile network codes in American Samoa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>452</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>VN</td>\n",
       "      <td>List of mobile network codes in the Vietnam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>543</td>\n",
       "      <td>W Wallis and Futuna</td>\n",
       "      <td>WF</td>\n",
       "      <td>List of mobile network codes in Wallis and Futuna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>421</td>\n",
       "      <td>Y Yemen</td>\n",
       "      <td>YE</td>\n",
       "      <td>List of mobile network codes in the Yemen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>645</td>\n",
       "      <td>Z Zambia</td>\n",
       "      <td>ZM</td>\n",
       "      <td>List of mobile network codes in Zambia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>648</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>List of mobile network codes in Zimbabwe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mobile country code                                    Country ISO 3166  \\\n",
       "0                    289                                 A Abkhazia    GE-AB   \n",
       "1                    412                                Afghanistan       AF   \n",
       "2                    276                                    Albania       AL   \n",
       "3                    603                                    Algeria       DZ   \n",
       "4                    544  American Samoa (United States of America)       AS   \n",
       "..                   ...                                        ...      ...   \n",
       "247                  452                                    Vietnam       VN   \n",
       "248                  543                        W Wallis and Futuna       WF   \n",
       "249                  421                                    Y Yemen       YE   \n",
       "250                  645                                   Z Zambia       ZM   \n",
       "251                  648                                   Zimbabwe       ZW   \n",
       "\n",
       "                                  Mobile network codes National MNC authority  \\\n",
       "0             List of mobile network codes in Abkhazia                    NaN   \n",
       "1          List of mobile network codes in Afghanistan                    NaN   \n",
       "2              List of mobile network codes in Albania                    NaN   \n",
       "3              List of mobile network codes in Algeria                    NaN   \n",
       "4       List of mobile network codes in American Samoa                    NaN   \n",
       "..                                                 ...                    ...   \n",
       "247        List of mobile network codes in the Vietnam                    NaN   \n",
       "248  List of mobile network codes in Wallis and Futuna                    NaN   \n",
       "249          List of mobile network codes in the Yemen                    NaN   \n",
       "250             List of mobile network codes in Zambia                    NaN   \n",
       "251           List of mobile network codes in Zimbabwe                    NaN   \n",
       "\n",
       "                      Remarks  \n",
       "0    MCC is not listed by ITU  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "..                        ...  \n",
       "247                       NaN  \n",
       "248                       NaN  \n",
       "249                       NaN  \n",
       "250                       NaN  \n",
       "251                       NaN  \n",
       "\n",
       "[252 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://en.wikipedia.org/wiki/Mobile_country_code\"\n",
    "pd.read_html(url,match=\"Country\",header=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in d:\\pythoncode\\venv\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in d:\\pythoncode\\venv\\lib\\site-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "### In terms to read All xlsx file:- Excel file we need to import a Libary called \n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel=pd.read_excel('data.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel.to_pickle(\"df_excel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Krish</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jack</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age\n",
       "0  Krish   32\n",
       "1   Jack   34\n",
       "2   John   31"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"df_excel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# For data manipulation and analysis\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m        \u001b[38;5;66;03m# For SQLite database\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m       \u001b[38;5;66;03m# For API data fetching\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 1. READING CSV FILES\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Reading CSV Files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "### ######  EXAMPLES OF RESOURCE AND ALL READ DATA FROM ANOTHER RESOURCES ###########\n",
    "\n",
    "# Importing Required Libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import sqlite3        # For SQLite database\n",
    "import requests       # For API data fetching\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. READING CSV FILES\n",
    "# --------------------------------------------------------------\n",
    "print(\"1. Reading CSV Files\")\n",
    "df_csv = pd.read_csv('data.csv')  # Replace 'data.csv' with your file path\n",
    "print(\"CSV Data (First 5 Rows):\")\n",
    "print(df_csv.head())  # Display the first 5 rows\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. READING EXCEL FILES\n",
    "# --------------------------------------------------------------\n",
    "print(\"2. Reading Excel Files\")\n",
    "df_excel = pd.read_excel('data.xlsx', sheet_name='Sheet1')  # Replace 'data.xlsx'\n",
    "print(\"Excel Data (First 5 Rows):\")\n",
    "print(df_excel.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3. READING JSON FILES\n",
    "# --------------------------------------------------------------\n",
    "print(\"3. Reading JSON Files\")\n",
    "df_json = pd.read_json('data.json')  # Replace 'data.json' with your JSON file\n",
    "print(\"JSON Data (First 5 Rows):\")\n",
    "print(df_json.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4. READING DATA FROM DATABASES\n",
    "# --------------------------------------------------------------\n",
    "print(\"4. Reading Data from Databases\")\n",
    "# Creating an SQLite connection (Replace 'database.db' and 'table_name')\n",
    "connection = sqlite3.connect('database.db')\n",
    "df_sql = pd.read_sql_query(\"SELECT * FROM table_name\", connection)  # Replace 'table_name'\n",
    "print(\"SQL Data (First 5 Rows):\")\n",
    "print(df_sql.head())\n",
    "connection.close()\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5. READING DATA FROM APIs\n",
    "# --------------------------------------------------------------\n",
    "print(\"5. Reading Data from APIs\")\n",
    "# Replace with a real API URL\n",
    "response = requests.get(\"https://api.example.com/data\")\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    df_api = pd.DataFrame(data)\n",
    "    print(\"API Data (First 5 Rows):\")\n",
    "    print(df_api.head())\n",
    "else:\n",
    "    print(\"Failed to fetch API data\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6. READING TEXT FILES (Tab-Delimited Example)\n",
    "# --------------------------------------------------------------\n",
    "print(\"6. Reading Text Files\")\n",
    "df_txt = pd.read_csv('data.txt', delimiter='\\t')  # Replace 'data.txt' with your file path\n",
    "print(\"Text Data (First 5 Rows):\")\n",
    "print(df_txt.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 7. READING HTML TABLES\n",
    "# --------------------------------------------------------------\n",
    "print(\"7. Reading HTML Tables\")\n",
    "url = 'https://example.com/data'  # Replace with a real URL containing tables\n",
    "try:\n",
    "    df_html = pd.read_html(url)[0]  # Reads the first table on the page\n",
    "    print(\"HTML Table Data (First 5 Rows):\")\n",
    "    print(df_html.head())\n",
    "except Exception as e:\n",
    "    print(\"Failed to read HTML table:\", e)\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 8. READING PARQUET FILES\n",
    "# --------------------------------------------------------------\n",
    "print(\"8. Reading Parquet Files\")\n",
    "# Replace 'data.parquet' with your file path\n",
    "df_parquet = pd.DataFrame({'sample': [1, 2, 3]})  # Dummy data for demonstration\n",
    "df_parquet.to_parquet('data.parquet')  # Saving dummy data to test\n",
    "df_parquet_read = pd.read_parquet('data.parquet')\n",
    "print(\"Parquet Data (First 5 Rows):\")\n",
    "print(df_parquet_read.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 9. READING PICKLE FILES\n",
    "# --------------------------------------------------------------\n",
    "print(\"9. Reading Pickle Files\")\n",
    "# Replace 'data.pkl' with your file path\n",
    "df_pickle = pd.DataFrame({'sample': [4, 5, 6]})  # Dummy data for demonstration\n",
    "df_pickle.to_pickle('data.pkl')  # Saving dummy data to test\n",
    "df_pickle_read = pd.read_pickle('data.pkl')\n",
    "print(\"Pickle Data (First 5 Rows):\")\n",
    "print(df_pickle_read.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 10. COMBINING DATA FROM MULTIPLE SOURCES\n",
    "# --------------------------------------------------------------\n",
    "print(\"10. Combining Data from Multiple Sources\")\n",
    "# Concatenating CSV and Excel data as an example\n",
    "df_combined = pd.concat([df_csv, df_excel], axis=0)  # Ensure both have compatible columns\n",
    "print(\"Combined Data (First 5 Rows):\")\n",
    "print(df_combined.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 11. DATA CLEANING AND PREPARATION\n",
    "# --------------------------------------------------------------\n",
    "print(\"11. Data Cleaning and Preparation\")\n",
    "# Handling missing values\n",
    "df_combined_cleaned = df_combined.dropna()  # Dropping rows with missing values\n",
    "print(\"Cleaned Data (First 5 Rows):\")\n",
    "print(df_combined_cleaned.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 12. DATA TRANSFORMATION (Grouping and Aggregation)\n",
    "# --------------------------------------------------------------\n",
    "print(\"12. Data Transformation (Grouping and Aggregation)\")\n",
    "# Example: Grouping by a column (Replace 'category' with your column name)\n",
    "if 'category' in df_combined_cleaned.columns:\n",
    "    grouped_data = df_combined_cleaned.groupby('category').sum()  # Aggregating numeric columns\n",
    "    print(\"Grouped Data (Sum by Category):\")\n",
    "    print(grouped_data)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# CONCLUSION\n",
    "# --------------------------------------------------------------\n",
    "print(\"All operations were successfully performed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random float (0 to 1): 0.12228651958874126\n",
      "Random integer (10 to 20): 20\n",
      "Random float (2.5 to 5.5): 3.4792540598127086\n",
      "Random color: red\n",
      "Random sample of colors: ['blue', 'green']\n",
      "Shuffled deck: [3, 1, 4, 5, 2]\n",
      "Seeded random integer: 2\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Random float between 0 and 1\n",
    "print(\"Random float (0 to 1):\", random.random())\n",
    "\n",
    "# Random integer between 10 and 20\n",
    "print(\"Random integer (10 to 20):\", random.randint(10, 20))\n",
    "\n",
    "# Random float between 2.5 and 5.5\n",
    "print(\"Random float (2.5 to 5.5):\", random.uniform(2.5, 5.5))\n",
    "\n",
    "# Random choice from a list\n",
    "colors = ['red', 'blue', 'green']\n",
    "print(\"Random color:\", random.choice(colors))\n",
    "\n",
    "# Random sample of 2 elements\n",
    "print(\"Random sample of colors:\", random.sample(colors, 2))\n",
    "\n",
    "# Shuffle a list\n",
    "deck = [1, 2, 3, 4, 5]\n",
    "random.shuffle(deck)\n",
    "print(\"Shuffled deck:\", deck)\n",
    "\n",
    "# Using a seed for reproducibility\n",
    "random.seed(42)\n",
    "print(\"Seeded random integer:\", random.randint(1, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "        manufacturer   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
      "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
      "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
      "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
      "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
      "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
      "\n",
      "   carb  \n",
      "0     4  \n",
      "1     4  \n",
      "2     1  \n",
      "3     1  \n",
      "4     2  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   manufacturer  32 non-null     object \n",
      " 1   mpg           32 non-null     float64\n",
      " 2   cyl           32 non-null     int64  \n",
      " 3   disp          32 non-null     float64\n",
      " 4   hp            32 non-null     int64  \n",
      " 5   drat          32 non-null     float64\n",
      " 6   wt            32 non-null     float64\n",
      " 7   qsec          32 non-null     float64\n",
      " 8   vs            32 non-null     int64  \n",
      " 9   am            32 non-null     int64  \n",
      " 10  gear          32 non-null     int64  \n",
      " 11  carb          32 non-null     int64  \n",
      "dtypes: float64(5), int64(6), object(1)\n",
      "memory usage: 3.1+ KB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "             mpg        cyl        disp          hp       drat         wt  \\\n",
      "count  32.000000  32.000000   32.000000   32.000000  32.000000  32.000000   \n",
      "mean   20.090625   6.187500  230.721875  146.687500   3.596563   3.217250   \n",
      "std     6.026948   1.785922  123.938694   68.562868   0.534679   0.978457   \n",
      "min    10.400000   4.000000   71.100000   52.000000   2.760000   1.513000   \n",
      "25%    15.425000   4.000000  120.825000   96.500000   3.080000   2.581250   \n",
      "50%    19.200000   6.000000  196.300000  123.000000   3.695000   3.325000   \n",
      "75%    22.800000   8.000000  326.000000  180.000000   3.920000   3.610000   \n",
      "max    33.900000   8.000000  472.000000  335.000000   4.930000   5.424000   \n",
      "\n",
      "            qsec         vs         am       gear     carb  \n",
      "count  32.000000  32.000000  32.000000  32.000000  32.0000  \n",
      "mean   17.848750   0.437500   0.406250   3.687500   2.8125  \n",
      "std     1.786943   0.504016   0.498991   0.737804   1.6152  \n",
      "min    14.500000   0.000000   0.000000   3.000000   1.0000  \n",
      "25%    16.892500   0.000000   0.000000   3.000000   2.0000  \n",
      "50%    17.710000   0.000000   0.000000   4.000000   2.0000  \n",
      "75%    18.900000   1.000000   1.000000   4.000000   4.0000  \n",
      "max    22.900000   1.000000   1.000000   5.000000   8.0000  \n",
      "\n",
      "Missing Values Count:\n",
      "manufacturer    0\n",
      "mpg             0\n",
      "cyl             0\n",
      "disp            0\n",
      "hp              0\n",
      "drat            0\n",
      "wt              0\n",
      "qsec            0\n",
      "vs              0\n",
      "am              0\n",
      "gear            0\n",
      "carb            0\n",
      "dtype: int64\n",
      "\n",
      "Number of Duplicate Rows: 0\n",
      "Duplicates removed. New shape of data: (32, 12)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Mazda RX4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Correlation matrix to explore relationships between numerical features\u001b[39;00m\n\u001b[0;32m     59\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m---> 60\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrelation Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32md:\\PYTHONCODE\\venv\\lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32md:\\PYTHONCODE\\venv\\lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32md:\\PYTHONCODE\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32md:\\PYTHONCODE\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Mazda RX4'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd                # For data manipulation and analysis\n",
    "import numpy as np                 # For numerical operations\n",
    "import matplotlib.pyplot as plt    # For data visualization\n",
    "import seaborn as sns              # For advanced data visualization\n",
    "\n",
    "# Load dataset\n",
    "# Replace 'your_dataset.csv' with the actual path to your dataset\n",
    "data = pd.read_csv('mtcars.csv')\n",
    "\n",
    "# Load the mtcars dataset\n",
    "mtcars = sns.load_dataset(\"mpg\")  # Use an appropriate dataset \n",
    "# Ensure only numeric columns are used in the Dataset \n",
    "mtcars_numeric = mtcars.select_dtypes(include=['number'])\n",
    "\n",
    "\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(data.head())  # Shows the first 5 rows\n",
    "print(\"\\nDataset Info:\")\n",
    "print(data.info())  # Data types, non-null counts\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(data.describe())  # Summary statistics for numerical columns\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values Count:\")\n",
    "print(data.isnull().sum())  # Count of missing values per column\n",
    "\n",
    "# Handle missing values\n",
    "# Example: Filling missing values in the 'Age' column with its median\n",
    "if 'Age' in data.columns:\n",
    "    data['Age'] = data['Age'].fillna(data['Age'].median())\n",
    "    print(\"\\nMissing values in 'Age' column filled with median.\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\nNumber of Duplicate Rows:\", data.duplicated().sum())\n",
    "data = data.drop_duplicates()  # Remove duplicate rows\n",
    "print(\"Duplicates removed. New shape of data:\", data.shape)\n",
    "\n",
    "# Visualize distributions of numerical columns\n",
    "if 'Age' in data.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(data['Age'], kde=True, bins=20, color='blue')\n",
    "    plt.title(\"Distribution of Age\")\n",
    "    plt.xlabel(\"Age\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "# Boxplot to detect outliers in a numerical column\n",
    "if 'Fare' in data.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(data['Fare'], color='green')\n",
    "    plt.title(\"Boxplot of Fare\")\n",
    "    plt.xlabel(\"Fare\")\n",
    "    plt.show()\n",
    "\n",
    "# Correlation matrix to explore relationships between numerical features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot to analyze relationships between two variables\n",
    "if 'Age' in data.columns and 'Fare' in data.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=data['Age'], y=data['Fare'], hue=data['Survived'] if 'Survived' in data.columns else None)\n",
    "    plt.title(\"Scatter Plot: Age vs. Fare\")\n",
    "    plt.xlabel(\"Age\")\n",
    "    plt.ylabel(\"Fare\")\n",
    "    plt.show()\n",
    "\n",
    "# Pie chart to visualize proportions of a categorical column\n",
    "if 'Survived' in data.columns:\n",
    "    survived_counts = data['Survived'].value_counts()\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.pie(survived_counts, labels=['Not Survived', 'Survived'], autopct='%1.1f%%', colors=['red', 'green'])\n",
    "    plt.title(\"Survival Proportion\")\n",
    "    plt.show()\n",
    "\n",
    "# Bar chart for categorical data\n",
    "if 'Pclass' in data.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(x=data['Pclass'], palette='viridis')\n",
    "    plt.title(\"Passenger Class Distribution\")\n",
    "    plt.xlabel(\"Passenger Class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "# Grouping and aggregation example\n",
    "if 'Pclass' in data.columns and 'Fare' in data.columns:\n",
    "    grouped_data = data.groupby('Pclass')['Fare'].mean()\n",
    "    print(\"\\nAverage Fare by Passenger Class:\")\n",
    "    print(grouped_data)\n",
    "\n",
    "    # Bar plot for grouped data\n",
    "    grouped_data.plot(kind='bar', color='purple', figsize=(8, 5))\n",
    "    plt.title(\"Average Fare by Passenger Class\")\n",
    "    plt.xlabel(\"Passenger Class\")\n",
    "    plt.ylabel(\"Average Fare\")\n",
    "    plt.show()\n",
    "\n",
    "# Export cleaned data\n",
    "data.to_csv('cleaned_dataset.csv', index=False)  # Save the cleaned dataset\n",
    "print(\"\\nCleaned dataset saved as 'cleaned_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
